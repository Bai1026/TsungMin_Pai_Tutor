import streamlit as st
import os
from index_rag import LawRAGPipeline
import pandas as pd

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="æ³•å¾‹ RAG æª¢ç´¢ç³»çµ±",
    page_icon="âš–ï¸",
    layout="wide"
)

# åˆå§‹åŒ– session state
if 'rag_pipeline' not in st.session_state:
    st.session_state.rag_pipeline = None
if 'vectorstore_loaded' not in st.session_state:
    st.session_state.vectorstore_loaded = False

def load_rag_pipeline():
    """è¼‰å…¥ RAG pipeline"""
    
    # å˜—è©¦å¤šç¨®æ–¹å¼ç²å– API é‡‘é‘°
    # OPENAI_API_KEY = None
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    if not OPENAI_API_KEY:
        try:
            from dotenv import load_dotenv
            load_dotenv()
            OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        except ImportError:
            pass

    if not OPENAI_API_KEY:
        st.error("âŒ ç„¡æ³•å–å¾— OPENAI_API_KEY")
        st.info("""
        è«‹è¨­å®š OPENAI_API_KEYï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ï¼š
        1. è¨­å®šç’°å¢ƒè®Šæ•¸ï¼š`export OPENAI_API_KEY="your-api-key"`
        2. å»ºç«‹ .env æ–‡ä»¶ï¼Œå…§å®¹ï¼š`OPENAI_API_KEY=your-api-key`
        3. æˆ–è€…ç›´æ¥åœ¨ç¨‹å¼ç¢¼ä¸­è¨­å®šï¼ˆä¸å»ºè­°ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒï¼‰
        """)
        return
    
    if st.session_state.rag_pipeline is None:
        with st.spinner('æ­£åœ¨åˆå§‹åŒ– RAG ç³»çµ±...'):
            st.session_state.rag_pipeline = LawRAGPipeline(OPENAI_API_KEY)
            
            # å˜—è©¦è¼‰å…¥ç¾æœ‰ç´¢å¼•
            try:
                st.session_state.rag_pipeline.load_existing_index()
                if st.session_state.rag_pipeline.vectorstore:
                    st.session_state.vectorstore_loaded = True
                    st.success("âœ… æˆåŠŸè¼‰å…¥ç¾æœ‰ç´¢å¼•ï¼")
                else:
                    st.warning("âš ï¸ æœªæ‰¾åˆ°ç¾æœ‰ç´¢å¼•ï¼Œè«‹å…ˆå»ºç«‹ç´¢å¼•")
            except Exception as e:
                st.error(f"âŒ è¼‰å…¥ç´¢å¼•å¤±æ•—ï¼š{e}")

def display_retrieved_data(retrieved_docs, scores=None):
    """é¡¯ç¤ºæª¢ç´¢åˆ°çš„è³‡æ–™"""
    st.subheader("ğŸ” æª¢ç´¢åˆ°çš„ç›¸é—œè³‡æ–™")
    
    if not retrieved_docs:
        st.warning("æ²’æœ‰æ‰¾åˆ°ç›¸é—œè³‡æ–™")
        return
    
    # æª¢ç´¢çµ±è¨ˆè³‡è¨Š
    st.subheader("ğŸ“ˆ æª¢ç´¢çµ±è¨ˆç¸½è¦½")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æª¢ç´¢ç‰‡æ®µæ•¸", len(retrieved_docs))
    
    with col2:
        total_chars = sum(len(doc.page_content) for doc in retrieved_docs)
        st.metric("ç¸½å­—ç¬¦æ•¸", f"{total_chars:,}")
    
    with col3:
        if scores:
            avg_score = sum(scores) / len(scores)
            st.metric("å¹³å‡ç›¸ä¼¼åº¦", f"{avg_score:.4f}")
    
    with col4:
        unique_sources = len(set(doc.metadata.get('title', 'æœªçŸ¥') for doc in retrieved_docs))
        st.metric("ä¾†æºæ–‡ä»¶æ•¸", unique_sources)
    
    # è©³ç´°ç¸½è¦½è¡¨æ ¼ (åƒ test_data_retrieval.py)
    st.subheader("ğŸ“Š æª¢ç´¢çµæœè©³ç´°ç¸½è¦½")
    overview_data = []
    for i, doc in enumerate(retrieved_docs):
        score = scores[i] if scores else "N/A"
        # å…§å®¹é è¦½ (å‰100å­—ç¬¦)
        content_preview = doc.page_content[:100].replace('\n', ' ') + ("..." if len(doc.page_content) > 100 else "")
        
        overview_data.append({
            "æ’å": i + 1,
            "ç›¸ä¼¼åº¦åˆ†æ•¸": f"{score:.4f}" if scores else "N/A",
            "æ¨™é¡Œ": doc.metadata.get('title', 'æœªçŸ¥'),
            "ç« ç¯€": doc.metadata.get('section', 'æœªçŸ¥'),
            "é¡Œç›®ç·¨è™Ÿ": doc.metadata.get('question_number', 'æœªçŸ¥'),
            "é¡å‹": doc.metadata.get('type', 'æœªçŸ¥'),
            "å…§å®¹é•·åº¦": f"{len(doc.page_content)} å­—å…ƒ",
            "å…§å®¹é è¦½": content_preview
        })
    
    df = pd.DataFrame(overview_data)
    st.dataframe(df, use_container_width=True, height=300)
    
    # æª¢ç´¢å“è³ªåˆ†æ
    if scores:
        st.subheader("ğŸ“Š ç›¸ä¼¼åº¦åˆ†æ•¸åˆ†æ")
        col1, col2 = st.columns(2)
        
        with col1:
            # åˆ†æ•¸åˆ†å¸ƒåœ–
            score_df = pd.DataFrame({
                "ç‰‡æ®µ": [f"ç‰‡æ®µ {i+1}" for i in range(len(scores))],
                "ç›¸ä¼¼åº¦åˆ†æ•¸": scores
            })
            st.bar_chart(score_df.set_index("ç‰‡æ®µ"))
        
        with col2:
            # åˆ†æ•¸çµ±è¨ˆ
            st.metric("æœ€é«˜ç›¸ä¼¼åº¦", f"{max(scores):.4f}")
            st.metric("æœ€ä½ç›¸ä¼¼åº¦", f"{min(scores):.4f}")
            st.metric("åˆ†æ•¸ç¯„åœ", f"{max(scores) - min(scores):.4f}")
            
            # åˆ†æ•¸å“è³ªè©•ä¼°
            if max(scores) > 0.8:
                quality = "ğŸŸ¢ å„ªç§€"
            elif max(scores) > 0.6:
                quality = "ğŸŸ¡ è‰¯å¥½"
            else:
                quality = "ğŸ”´ éœ€æ”¹å–„"
            st.metric("æª¢ç´¢å“è³ª", quality)
    
    # é¡¯ç¤ºå®Œæ•´å…§å®¹çš„é¸é …
    st.subheader("ğŸ“„ è©³ç´°å…§å®¹æª¢è¦–")
    
    # é¸æ“‡é¡¯ç¤ºæ–¹å¼
    display_mode = st.radio(
        "é¸æ“‡é¡¯ç¤ºæ–¹å¼ï¼š",
        ["æ¨™ç±¤é æ¨¡å¼", "é€£çºŒé¡¯ç¤ºæ¨¡å¼", "è¡¨æ ¼æ¨¡å¼"],
        horizontal=True
    )
    
    if display_mode == "æ¨™ç±¤é æ¨¡å¼":
        # åŸæœ¬çš„æ¨™ç±¤é é¡¯ç¤ºï¼Œä½†åŠ ä¸Šæ›´å¤šè³‡è¨Š
        tab_labels = []
        for i in range(len(retrieved_docs)):
            score_text = f"(åˆ†æ•¸: {scores[i]:.3f})" if scores else ""
            title_short = retrieved_docs[i].metadata.get('title', 'æœªçŸ¥')[:20]
            tab_labels.append(f"ç‰‡æ®µ {i+1} {score_text}")
        
        tabs = st.tabs(tab_labels)
        
        for i, (tab, doc) in enumerate(zip(tabs, retrieved_docs)):
            with tab:
                display_single_document(doc, scores[i] if scores else None, i+1)
    
    elif display_mode == "é€£çºŒé¡¯ç¤ºæ¨¡å¼":
        # é€£çºŒé¡¯ç¤ºæ‰€æœ‰æ–‡ä»¶ (æ¨¡æ“¬ test_data_retrieval.py çš„è¼¸å‡ºæ ¼å¼)
        st.markdown("### ğŸ” è©³ç´°æª¢ç´¢çµæœ (é€£çºŒé¡¯ç¤º)")
        
        for i, doc in enumerate(retrieved_docs):
            st.markdown("---")
            
            # æ¨¡æ“¬ test_data_retrieval.py çš„æ ¼å¼
            st.markdown(f"#### ç‰‡æ®µ {i+1}:")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**æ¨™é¡Œï¼š** {doc.metadata.get('title', 'æœªçŸ¥')}")
                st.write(f"**ç« ç¯€ï¼š** {doc.metadata.get('section', 'æœªçŸ¥')}")
                st.write(f"**é¡Œç›®ç·¨è™Ÿï¼š** {doc.metadata.get('question_number', 'æœªçŸ¥')}")
                st.write(f"**é¡å‹ï¼š** {doc.metadata.get('type', 'æœªçŸ¥')}")
            
            with col2:
                st.write(f"**å…§å®¹é•·åº¦ï¼š** {len(doc.page_content)} å­—å…ƒ")
                if scores:
                    st.write(f"**ç›¸ä¼¼åº¦åˆ†æ•¸ï¼š** {scores[i]:.4f}")
            
            # å…§å®¹é è¦½ (åƒ test_data_retrieval.py)
            st.write("**å…§å®¹é è¦½ï¼š**")
            st.text("â”€" * 40)
            preview = doc.page_content[:300]
            st.text(preview)
            if len(doc.page_content) > 300:
                st.text("...")
            st.text("â”€" * 40)
            
            # å±•é–‹æŸ¥çœ‹å®Œæ•´å…§å®¹
            with st.expander(f"ï¿½ æŸ¥çœ‹ç‰‡æ®µ {i+1} å®Œæ•´å…§å®¹"):
                display_single_document(doc, scores[i] if scores else None, i+1)
    
    elif display_mode == "è¡¨æ ¼æ¨¡å¼":
        # è¡¨æ ¼æ¨¡å¼é¡¯ç¤ºå®Œæ•´å…§å®¹
        display_table_mode(retrieved_docs, scores)

def display_single_document(doc, score, rank):
    """é¡¯ç¤ºå–®å€‹æ–‡ä»¶çš„è©³ç´°è³‡è¨Š"""
    
    # è©³ç´°è³‡è¨Šæ¨™é¡Œ
    st.markdown(f"### ğŸ“„ ç‰‡æ®µ {rank} è©³ç´°è³‡è¨Š")
    
    # åŸºæœ¬è³‡è¨Šå€å¡Š
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ’å", f"#{rank}")
        if score is not None:
            st.metric("ç›¸ä¼¼åº¦åˆ†æ•¸", f"{score:.4f}")
    
    with col2:
        st.metric("å…§å®¹é•·åº¦", f"{len(doc.page_content)} å­—å…ƒ")
        st.metric("å­—æ•¸ä¼°è¨ˆ", f"~{len(doc.page_content.replace(' ', ''))}")
    
    with col3:
        st.info(f"""
        **æ¨™é¡Œï¼š** {doc.metadata.get('title', 'æœªçŸ¥')}  
        **ç« ç¯€ï¼š** {doc.metadata.get('section', 'æœªçŸ¥')}
        """)
    
    with col4:
        st.info(f"""
        **é¡Œç›®ç·¨è™Ÿï¼š** {doc.metadata.get('question_number', 'æœªçŸ¥')}  
        **é¡å‹ï¼š** {doc.metadata.get('type', 'æœªçŸ¥')}
        """)
    
    # å®Œæ•´ Metadata å±•é–‹
    with st.expander(f"ğŸ” å®Œæ•´ Metadata (ç‰‡æ®µ {rank})"):
        st.json(doc.metadata)
        
        # é¡å¤–çš„ metadata åˆ†æ
        st.subheader("Metadata åˆ†æ")
        metadata_df = pd.DataFrame([
            {"å±¬æ€§": key, "å€¼": str(value)} 
            for key, value in doc.metadata.items()
        ])
        st.dataframe(metadata_df, use_container_width=True)
    
    # å…§å®¹é è¦½ (åƒ test_data_retrieval.py ä¸€æ¨£)
    st.subheader("ğŸ“– å…§å®¹é è¦½ (å‰ 300 å­—å…ƒ)")
    preview = doc.page_content[:300]
    st.text_area(
        f"ç‰‡æ®µ {rank} å…§å®¹é è¦½",
        value=preview + ("..." if len(doc.page_content) > 300 else ""),
        height=150,
        key=f"preview_{rank}",
        disabled=True
    )
    
    # å®Œæ•´å…§å®¹
    st.subheader("ğŸ“ å®Œæ•´å…§å®¹")
    
    # å…§å®¹é¡¯ç¤ºé¸é …
    col1, col2 = st.columns(2)
    with col1:
        height_option = st.selectbox(
            f"é¡¯ç¤ºé«˜åº¦ï¼š",
            [200, 300, 400, 500, 600],
            index=2,
            key=f"height_{rank}"
        )
    
    with col2:
        show_line_numbers = st.checkbox(f"é¡¯ç¤ºè¡Œè™Ÿ (ç‰‡æ®µ {rank})", key=f"line_numbers_{rank}")
    
    # å®Œæ•´å…§å®¹é¡¯ç¤º
    if show_line_numbers:
        # åŠ ä¸Šè¡Œè™Ÿçš„é¡¯ç¤º
        lines = doc.page_content.split('\n')
        content_with_lines = '\n'.join([f"{i+1:3d}: {line}" for i, line in enumerate(lines)])
        st.text_area(
            f"ç‰‡æ®µ {rank} å®Œæ•´å…§å®¹ (å«è¡Œè™Ÿ)",
            value=content_with_lines,
            height=height_option,
            key=f"content_full_lines_{rank}",
            disabled=True
        )
    else:
        st.text_area(
            f"ç‰‡æ®µ {rank} å®Œæ•´å…§å®¹",
            value=doc.page_content,
            height=height_option,
            key=f"content_full_{rank}",
            disabled=True
        )
    
    # å…§å®¹åˆ†æ
    with st.expander(f"ğŸ“Š å…§å®¹åˆ†æ (ç‰‡æ®µ {rank})"):
        col1, col2 = st.columns(2)
        
        with col1:
            # å­—ç¬¦çµ±è¨ˆ
            st.subheader("å­—ç¬¦çµ±è¨ˆ")
            char_stats = {
                "ç¸½å­—ç¬¦æ•¸": len(doc.page_content),
                "ç¸½è¡Œæ•¸": len(doc.page_content.split('\n')),
                "ä¸­æ–‡å­—ç¬¦æ•¸": len([c for c in doc.page_content if '\u4e00' <= c <= '\u9fff']),
                "è‹±æ–‡å­—ç¬¦æ•¸": len([c for c in doc.page_content if c.isalpha() and ord(c) < 256]),
                "æ•¸å­—å­—ç¬¦æ•¸": len([c for c in doc.page_content if c.isdigit()]),
                "æ¨™é»ç¬¦è™Ÿæ•¸": len([c for c in doc.page_content if not c.isalnum() and not c.isspace()])
            }
            
            for key, value in char_stats.items():
                st.metric(key, value)
        
        with col2:
            # é—œéµè©åˆ†æ
            st.subheader("å¯èƒ½çš„é—œéµè©")
            # ç°¡å–®çš„é—œéµè©æå–
            import re
            words = re.findall(r'[\u4e00-\u9fff]+', doc.page_content)  # æå–ä¸­æ–‡è©
            word_freq = pd.Series(words).value_counts().head(10)
            if len(word_freq) > 0:
                st.bar_chart(word_freq)
            else:
                st.write("æœªæ‰¾åˆ°æ˜é¡¯çš„é—œéµè©")
    
    # å¯è¤‡è£½çš„æ–‡æœ¬ (å¤šç¨®æ ¼å¼)
    with st.expander(f"ğŸ“‹ å¯è¤‡è£½æ–‡æœ¬ (ç‰‡æ®µ {rank})"):
        copy_format = st.radio(
            "é¸æ“‡è¤‡è£½æ ¼å¼ï¼š",
            ["ç´”æ–‡æœ¬", "Markdown", "JSONæ ¼å¼"],
            key=f"copy_format_{rank}",
            horizontal=True
        )
        
        if copy_format == "ç´”æ–‡æœ¬":
            st.code(doc.page_content, language="text")
        elif copy_format == "Markdown":
            markdown_content = f"""# ç‰‡æ®µ {rank}

## Metadata
- **æ¨™é¡Œ**: {doc.metadata.get('title', 'æœªçŸ¥')}
- **ç« ç¯€**: {doc.metadata.get('section', 'æœªçŸ¥')}
- **é¡Œç›®ç·¨è™Ÿ**: {doc.metadata.get('question_number', 'æœªçŸ¥')}
- **é¡å‹**: {doc.metadata.get('type', 'æœªçŸ¥')}
- **ç›¸ä¼¼åº¦åˆ†æ•¸**: {score:.4f if score else 'N/A'}

## å…§å®¹
{doc.page_content}
"""
            st.code(markdown_content, language="markdown")
        else:  # JSONæ ¼å¼
            json_content = {
                "rank": rank,
                "similarity_score": score,
                "metadata": doc.metadata,
                "content": doc.page_content,
                "content_length": len(doc.page_content)
            }
            import json
            st.code(json.dumps(json_content, ensure_ascii=False, indent=2), language="json")

def display_table_mode(retrieved_docs, scores):
    """è¡¨æ ¼æ¨¡å¼é¡¯ç¤ºæ‰€æœ‰æª¢ç´¢è³‡æ–™"""
    st.markdown("**ğŸ“‹ æ‰€æœ‰æª¢ç´¢å…§å®¹ (è¡¨æ ¼æ ¼å¼)**")
    
    table_data = []
    for i, doc in enumerate(retrieved_docs):
        score = scores[i] if scores else "N/A"
        table_data.append({
            "æ’å": i + 1,
            "ç›¸ä¼¼åº¦åˆ†æ•¸": f"{score:.4f}" if scores else "N/A",
            "æ¨™é¡Œ": doc.metadata.get('title', 'æœªçŸ¥'),
            "ç« ç¯€": doc.metadata.get('section', 'æœªçŸ¥'),
            "é¡Œç›®ç·¨è™Ÿ": doc.metadata.get('question_number', 'æœªçŸ¥'),
            "é¡å‹": doc.metadata.get('type', 'æœªçŸ¥'),
            "å…§å®¹é•·åº¦": f"{len(doc.page_content)} å­—å…ƒ",
            "å®Œæ•´å…§å®¹": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
            "å®Œæ•´å…§å®¹(æœªæˆªæ–·)": doc.page_content
        })
    
    df = pd.DataFrame(table_data)
    
    # é¡¯ç¤ºé¸é …
    show_full_content = st.checkbox("é¡¯ç¤ºå®Œæ•´å…§å®¹ (è€Œéæˆªæ–·ç‰ˆæœ¬)")
    
    if show_full_content:
        # é¡¯ç¤ºåŒ…å«å®Œæ•´å…§å®¹çš„è¡¨æ ¼
        display_df = df.drop(columns=["å®Œæ•´å…§å®¹"])
        display_df = display_df.rename(columns={"å®Œæ•´å…§å®¹(æœªæˆªæ–·)": "å®Œæ•´å…§å®¹"})
    else:
        # é¡¯ç¤ºæˆªæ–·ç‰ˆæœ¬
        display_df = df.drop(columns=["å®Œæ•´å…§å®¹(æœªæˆªæ–·)"])
    
    st.dataframe(
        display_df, 
        use_container_width=True,
        height=400
    )
    
    # ä¸‹è¼‰æŒ‰éˆ•
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰æª¢ç´¢çµæœ (CSV)",
        data=csv,
        file_name=f"retrieval_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )

def display_vectorstore_stats():
    """é¡¯ç¤ºå‘é‡è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
    if st.session_state.vectorstore_loaded and st.session_state.rag_pipeline:
        try:
            collection = st.session_state.rag_pipeline.vectorstore._collection
            results = collection.get(include=['documents', 'metadatas'])
            total_docs = len(results['documents'])
            
            st.sidebar.metric("ğŸ“Š è³‡æ–™åº«çµ±è¨ˆ", f"{total_docs} å€‹æ–‡ä»¶ç‰‡æ®µ")
            
            # åˆ†ææ–‡ä»¶é¡å‹
            types = [meta.get('type', 'æœªçŸ¥') for meta in results['metadatas']]
            type_counts = pd.Series(types).value_counts()
            
            st.sidebar.subheader("ğŸ“ˆ æ–‡ä»¶é¡å‹åˆ†å¸ƒ")
            st.sidebar.bar_chart(type_counts)
            
        except Exception as e:
            st.sidebar.error(f"ç„¡æ³•å–å¾—çµ±è¨ˆè³‡è¨Šï¼š{e}")

def main():
    # æ¨™é¡Œ
    st.title("âš–ï¸ æ³•å¾‹ RAG æª¢ç´¢ç³»çµ±")
    st.markdown("è¼¸å…¥æ³•å¾‹å•é¡Œï¼ŒæŸ¥çœ‹ç³»çµ±æª¢ç´¢åˆ°çš„ç›¸é—œè³‡æ–™ç‰‡æ®µ")
    
    # è¼‰å…¥ RAG pipeline
    load_rag_pipeline()
    
    # å´é‚Šæ¬„
    st.sidebar.title("ğŸ”§ ç³»çµ±è¨­å®š")
    
    # é¡¯ç¤ºç³»çµ±ç‹€æ…‹
    if st.session_state.vectorstore_loaded:
        st.sidebar.success("âœ… ç³»çµ±å·²å°±ç·’")
        display_vectorstore_stats()
    else:
        st.sidebar.error("âŒ ç³»çµ±æœªå°±ç·’")
        
        # å»ºç«‹ç´¢å¼•æŒ‰éˆ•
        if st.sidebar.button("ğŸ”„ å»ºç«‹æ–°ç´¢å¼•"):
            data_file = "/Users/zoungming/Desktop/Codes/TsungMin_Pai_Tutor/Law_Bot/rag/data/qa.txt"
            if os.path.exists(data_file):
                with st.spinner('æ­£åœ¨å»ºç«‹ç´¢å¼•...'):
                    try:
                        st.session_state.rag_pipeline.index_documents(data_file)
                        st.session_state.vectorstore_loaded = True
                        st.rerun()
                    except Exception as e:
                        st.error(f"å»ºç«‹ç´¢å¼•å¤±æ•—ï¼š{e}")
            else:
                st.error(f"æ‰¾ä¸åˆ°è³‡æ–™æ–‡ä»¶ï¼š{data_file}")
    
    # æª¢ç´¢è¨­å®š
    st.sidebar.subheader("ğŸ›ï¸ æª¢ç´¢è¨­å®š")
    k_value = st.sidebar.slider("æª¢ç´¢ç‰‡æ®µæ•¸é‡", 1, 10, 5)
    show_scores = st.sidebar.checkbox("é¡¯ç¤ºç›¸ä¼¼åº¦åˆ†æ•¸", True)
    
    # ä¸»è¦ä»‹é¢
    if st.session_state.vectorstore_loaded:
        # å•é¡Œè¼¸å…¥
        st.subheader("â“ è¼¸å…¥æ‚¨çš„æ³•å¾‹å•é¡Œ")
        question = st.text_input(
            "è«‹è¼¸å…¥å•é¡Œï¼š",
            placeholder="ä¾‹å¦‚ï¼šç”²ç«Šå–ä»–äººè²¡ç‰©å¾Œè¢«ç™¼ç¾ï¼Œç‚ºäº†è„«å…é€®æ•è€Œä½¿ç”¨æš´åŠ›ï¼Œé€™æ¨£çš„è¡Œç‚ºå¦‚ä½•å®šç½ªï¼Ÿ"
        )
        
        # ç¯„ä¾‹å•é¡ŒæŒ‰éˆ•
        st.subheader("ğŸ’¡ ç¯„ä¾‹å•é¡Œ")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ç«Šç›œç½ªæ§‹æˆè¦ä»¶"):
                question = "ç«Šç›œç½ªçš„æ§‹æˆè¦ä»¶æœ‰å“ªäº›ï¼Ÿ"
                st.rerun()
                
        with col2:
            if st.button("æº–å¼·ç›œç½ª"):
                question = "ä»€éº¼æ˜¯æº–å¼·ç›œç½ªï¼Ÿæ§‹æˆè¦ä»¶æœ‰å“ªäº›ï¼Ÿ"
                st.rerun()
                
        with col3:
            if st.button("ç«Šç›œèˆ‡å¼·ç›œå€åˆ¥"):
                question = "ç«Šç›œç½ªå’Œå¼·ç›œç½ªçš„å€åˆ¥æ˜¯ä»€éº¼ï¼Ÿ"
                st.rerun()
        
        # åŸ·è¡Œæª¢ç´¢
        if question:
            with st.spinner('æ­£åœ¨æª¢ç´¢ç›¸é—œè³‡æ–™...'):
                try:
                    if show_scores:
                        results = st.session_state.rag_pipeline.vectorstore.similarity_search_with_score(
                            question, k=k_value
                        )
                        retrieved_docs = [doc for doc, score in results]
                        scores = [score for doc, score in results]
                    else:
                        retrieved_docs = st.session_state.rag_pipeline.vectorstore.similarity_search(
                            question, k=k_value
                        )
                        scores = None
                    
                    # é¡¯ç¤ºæª¢ç´¢çµæœ
                    display_retrieved_data(retrieved_docs, scores)
                    
                    # QA Validation å·¥å…·
                    st.subheader("ğŸ” QA Validation å·¥å…·")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        # åŒ¯å‡ºæª¢ç´¢è³‡æ–™ç‚º JSON
                        export_data = []
                        for i, doc in enumerate(retrieved_docs):
                            export_data.append({
                                "rank": i + 1,
                                "similarity_score": scores[i] if scores else None,
                                "question": question,
                                "metadata": doc.metadata,
                                "content": doc.page_content,
                                "content_length": len(doc.page_content)
                            })
                        
                        import json
                        json_data = json.dumps(export_data, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="ğŸ“„ åŒ¯å‡ºæª¢ç´¢è³‡æ–™ (JSON)",
                            data=json_data,
                            file_name=f"qa_validation_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                    
                    with col2:
                        # æª¢ç´¢å“è³ªåˆ†æ
                        if scores:
                            avg_score = sum(scores) / len(scores)
                            max_score = max(scores)
                            min_score = min(scores)
                            
                            st.metric("å¹³å‡ç›¸ä¼¼åº¦", f"{avg_score:.4f}")
                            st.metric("æœ€é«˜ç›¸ä¼¼åº¦", f"{max_score:.4f}")
                            st.metric("æœ€ä½ç›¸ä¼¼åº¦", f"{min_score:.4f}")
                    
                    # æª¢ç´¢è³‡æ–™çµ±è¨ˆåˆ†æ
                    with st.expander("ğŸ“Š æª¢ç´¢è³‡æ–™çµ±è¨ˆåˆ†æ"):
                        # å…§å®¹é•·åº¦åˆ†å¸ƒ
                        lengths = [len(doc.page_content) for doc in retrieved_docs]
                        st.subheader("å…§å®¹é•·åº¦åˆ†å¸ƒ")
                        st.bar_chart(pd.DataFrame({"ç‰‡æ®µ": range(1, len(lengths)+1), "é•·åº¦": lengths}).set_index("ç‰‡æ®µ"))
                        
                        # æ–‡ä»¶é¡å‹åˆ†æ
                        types = [doc.metadata.get('type', 'æœªçŸ¥') for doc in retrieved_docs]
                        type_counts = pd.Series(types).value_counts()
                        if len(type_counts) > 1:
                            st.subheader("æª¢ç´¢æ–‡ä»¶é¡å‹åˆ†å¸ƒ")
                            st.bar_chart(type_counts)
                        
                        # ä¾†æºåˆ†æ
                        sources = [doc.metadata.get('title', 'æœªçŸ¥') for doc in retrieved_docs]
                        source_counts = pd.Series(sources).value_counts()
                        if len(source_counts) > 1:
                            st.subheader("ä¾†æºæ–‡ä»¶åˆ†å¸ƒ")
                            st.bar_chart(source_counts)
                    
                    # é¡¯ç¤ºå®Œæ•´å•ç­”ï¼ˆå¯é¸ï¼‰
                    if st.checkbox("ğŸ¤– é¡¯ç¤º AI å›ç­”"):
                        with st.spinner('æ­£åœ¨ç”¢ç”Ÿå›ç­”...'):
                            try:
                                result = st.session_state.rag_pipeline.query(question)
                                st.subheader("ğŸ¯ AI å›ç­”")
                                st.write(result['answer'])
                                
                                with st.expander("ğŸ“š åƒè€ƒè³‡æ–™ä¾†æº"):
                                    for i, doc in enumerate(result['source_documents']):
                                        st.write(f"{i+1}. {doc.metadata.get('title', 'æœªçŸ¥')} - {doc.metadata.get('section', 'æœªçŸ¥')}")
                                        
                            except Exception as e:
                                st.error(f"ç”¢ç”Ÿå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    
                except Exception as e:
                    st.error(f"æª¢ç´¢éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    else:
        st.warning("âš ï¸ è«‹å…ˆè¼‰å…¥æˆ–å»ºç«‹ç´¢å¼•æ‰èƒ½ä½¿ç”¨æª¢ç´¢åŠŸèƒ½")

if __name__ == "__main__":
    main()