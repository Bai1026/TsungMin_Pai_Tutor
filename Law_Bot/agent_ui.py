import streamlit as st
import os
from typing import Dict
import pandas as pd
from agent import LawBotAgent

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="âš–ï¸ æ³•å¾‹æ©Ÿå™¨äººä»£ç†",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ– session state
if 'agent' not in st.session_state:
    st.session_state.agent = None
if 'last_result' not in st.session_state:
    st.session_state.last_result = None

def load_agent():
    """è¼‰å…¥æ³•å¾‹æ©Ÿå™¨äººä»£ç†"""
    
    # å˜—è©¦å¤šç¨®æ–¹å¼ç²å– API é‡‘é‘°
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    if not OPENAI_API_KEY:
        try:
            from dotenv import load_dotenv
            load_dotenv()
            OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        except ImportError:
            pass

    if not OPENAI_API_KEY:
        st.error("âŒ ç„¡æ³•å–å¾— OPENAI_API_KEY")
        st.info("""
        è«‹è¨­å®š OPENAI_API_KEYï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ï¼š
        1. è¨­å®šç’°å¢ƒè®Šæ•¸ï¼š`export OPENAI_API_KEY="your-api-key"`
        2. å»ºç«‹ .env æ–‡ä»¶ï¼Œå…§å®¹ï¼š`OPENAI_API_KEY=your-api-key`
        """)
        return None
    
    if st.session_state.agent is None:
        with st.spinner('æ­£åœ¨åˆå§‹åŒ–æ³•å¾‹æ©Ÿå™¨äººä»£ç†...'):
            try:
                st.session_state.agent = LawBotAgent(OPENAI_API_KEY)
                st.success("âœ… æ³•å¾‹æ©Ÿå™¨äººä»£ç†åˆå§‹åŒ–æˆåŠŸï¼")
                return st.session_state.agent
            except Exception as e:
                st.error(f"âŒ åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
                return None
    
    return st.session_state.agent

def display_classification_result(result: Dict):
    """é¡¯ç¤ºåˆ†é¡ä¸»é¡Œçµæœ"""
    st.subheader("ğŸ¯ ä¸»é¡Œåˆ†é¡çµæœ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("é¸æ“‡çš„ä¸»é¡Œ", result['chosen_topic'])
    
    with col2:
        if result['data_file']:
            db_name = os.path.basename(result['data_file'])
            st.metric("ä½¿ç”¨è³‡æ–™åº«", db_name)
    
    # ä¸»é¡Œèªªæ˜
    if result['chosen_topic'] in st.session_state.agent.topic_to_file_mapping:
        # å¾ topic_metadata å–å¾—èªªæ˜
        from test_topic_module import topic_metadata
        if result['chosen_topic'] in topic_metadata:
            with st.expander("ğŸ“– ä¸»é¡Œè©³ç´°èªªæ˜"):
                st.write(topic_metadata[result['chosen_topic']])
    # ä¸»é¡Œé¸æ“‡åŸå› 
    if 'chosen_topic_reasoning' in result:
        st.subheader("ğŸ“ ä¸»é¡Œé¸æ“‡æ¨ç†")
        st.write(result['chosen_topic_reasoning'])

def display_reference_data(result: Dict):
    """é¡¯ç¤ºåƒè€ƒè³‡æ–™"""
    st.subheader("ğŸ“š åƒè€ƒè³‡æ–™")
    
    if not result['retrieved_docs']:
        st.warning("æ²’æœ‰æ‰¾åˆ°ç›¸é—œåƒè€ƒè³‡æ–™")
        return
    
    # åƒè€ƒè³‡æ–™çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æª¢ç´¢ç‰‡æ®µæ•¸", len(result['retrieved_docs']))
    
    with col2:
        total_chars = sum(len(doc.page_content) for doc in result['retrieved_docs'])
        st.metric("ç¸½å­—ç¬¦æ•¸", f"{total_chars:,}")
    
    with col3:
        unique_sources = len(set(doc.metadata.get('title', 'æœªçŸ¥') for doc in result['retrieved_docs']))
        st.metric("ä¾†æºæ–‡ä»¶æ•¸", unique_sources)
    
    with col4:
        avg_length = total_chars // len(result['retrieved_docs'])
        st.metric("å¹³å‡ç‰‡æ®µé•·åº¦", f"{avg_length:,}")
    
    # åƒè€ƒè³‡æ–™åˆ—è¡¨
    st.subheader("ğŸ“„ åƒè€ƒè³‡æ–™è©³ç´°å…§å®¹")
    
    # é¡¯ç¤ºæ–¹å¼é¸æ“‡
    display_mode = st.radio(
        "é¸æ“‡é¡¯ç¤ºæ–¹å¼ï¼š",
        ["å¡ç‰‡æ¨¡å¼", "è¡¨æ ¼æ¨¡å¼", "å®Œæ•´å…§å®¹"],
        horizontal=True
    )
    
    if display_mode == "å¡ç‰‡æ¨¡å¼":
        for i, doc in enumerate(result['retrieved_docs'], 1):
            with st.container():
                st.markdown(f"### ğŸ“„ åƒè€ƒè³‡æ–™ {i}")
                
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.info(f"""
                    **æ¨™é¡Œï¼š** {doc.metadata.get('title', 'æœªçŸ¥')}  
                    **ç« ç¯€ï¼š** {doc.metadata.get('section', 'æœªçŸ¥')}  
                    **é¡Œç›®ç·¨è™Ÿï¼š** {doc.metadata.get('question_number', 'æœªçŸ¥')}  
                    **é¡å‹ï¼š** {doc.metadata.get('type', 'æœªçŸ¥')}  
                    **å…§å®¹é•·åº¦ï¼š** {len(doc.page_content)} å­—å…ƒ
                    """)
                
                with col2:
                    # å…§å®¹é è¦½
                    preview = doc.page_content[:200] + ("..." if len(doc.page_content) > 200 else "")
                    st.text_area(
                        f"å…§å®¹é è¦½ {i}",
                        value=preview,
                        height=100,
                        key=f"preview_{i}",
                        disabled=True
                    )
                
                # å±•é–‹æŸ¥çœ‹å®Œæ•´å…§å®¹
                with st.expander(f"ğŸ” æŸ¥çœ‹åƒè€ƒè³‡æ–™ {i} å®Œæ•´å…§å®¹"):
                    st.text_area(
                        f"å®Œæ•´å…§å®¹ {i}",
                        value=doc.page_content,
                        height=300,
                        key=f"full_content_{i}",
                        disabled=True
                    )
                
                st.divider()
    
    elif display_mode == "è¡¨æ ¼æ¨¡å¼":
        # å»ºç«‹è¡¨æ ¼è³‡æ–™
        table_data = []
        for i, doc in enumerate(result['retrieved_docs'], 1):
            content_preview = doc.page_content[:100].replace('\n', ' ') + ("..." if len(doc.page_content) > 100 else "")
            table_data.append({
                "åºè™Ÿ": i,
                "æ¨™é¡Œ": doc.metadata.get('title', 'æœªçŸ¥'),
                "ç« ç¯€": doc.metadata.get('section', 'æœªçŸ¥'),
                "é¡Œç›®ç·¨è™Ÿ": doc.metadata.get('question_number', 'æœªçŸ¥'),
                "é¡å‹": doc.metadata.get('type', 'æœªçŸ¥'),
                "å…§å®¹é•·åº¦": f"{len(doc.page_content)} å­—å…ƒ",
                "å…§å®¹é è¦½": content_preview
            })
        
        df = pd.DataFrame(table_data)
        st.dataframe(df, use_container_width=True, height=400)
        
        # ä¸‹è¼‰æŒ‰éˆ•
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰åƒè€ƒè³‡æ–™ (CSV)",
            data=csv,
            file_name=f"reference_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    else:  # å®Œæ•´å…§å®¹æ¨¡å¼
        tabs = st.tabs([f"åƒè€ƒè³‡æ–™ {i}" for i in range(1, len(result['retrieved_docs']) + 1)])
        
        for i, (tab, doc) in enumerate(zip(tabs, result['retrieved_docs'])):
            with tab:
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.subheader("ğŸ“‹ æ–‡ä»¶è³‡è¨Š")
                    st.write(f"**æ¨™é¡Œï¼š** {doc.metadata.get('title', 'æœªçŸ¥')}")
                    st.write(f"**ç« ç¯€ï¼š** {doc.metadata.get('section', 'æœªçŸ¥')}")
                    st.write(f"**é¡Œç›®ç·¨è™Ÿï¼š** {doc.metadata.get('question_number', 'æœªçŸ¥')}")
                    st.write(f"**é¡å‹ï¼š** {doc.metadata.get('type', 'æœªçŸ¥')}")
                    st.write(f"**å…§å®¹é•·åº¦ï¼š** {len(doc.page_content)} å­—å…ƒ")
                    
                    # Metadata è©³ç´°è³‡è¨Š
                    with st.expander("ğŸ” å®Œæ•´ Metadata"):
                        st.json(doc.metadata)
                
                with col2:
                    st.subheader("ğŸ“ å®Œæ•´å…§å®¹")
                    st.text_area(
                        f"åƒè€ƒè³‡æ–™ {i+1} å®Œæ•´å…§å®¹",
                        value=doc.page_content,
                        height=400,
                        key=f"tab_content_{i}",
                        disabled=True
                    )

def display_ai_response(result: Dict):
    """é¡¯ç¤º AI å›ç­”"""
    st.subheader("ğŸ¤– AI å›ç­”")
    
    if result['answer']:
        # AI å›ç­”å…§å®¹
        st.markdown("### ğŸ’¡ å›ç­”å…§å®¹")
        st.write(result['answer'])
        
        # ä¾†æºæ–‡ä»¶
        if result['source_documents']:
            st.markdown("### ğŸ“– å›ç­”ä¾æ“šçš„ä¾†æºæ–‡ä»¶")
            for i, doc in enumerate(result['source_documents'], 1):
                title = doc.metadata.get('title', 'æœªçŸ¥')
                section = doc.metadata.get('section', 'æœªçŸ¥')
                st.write(f"{i}. **{title}** - {section}")
        
        # å›ç­”åˆ†æ
        with st.expander("ğŸ“Š å›ç­”åˆ†æ"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("å›ç­”å­—æ•¸", len(result['answer']))
            
            with col2:
                st.metric("ä½¿ç”¨ä¾†æºæ•¸", len(result['source_documents']) if result['source_documents'] else 0)
            
            with col3:
                # ç°¡å–®çš„å›ç­”å“è³ªè©•ä¼°
                word_count = len(result['answer'])
                if word_count > 200:
                    quality = "ğŸŸ¢ è©³ç´°"
                elif word_count > 100:
                    quality = "ğŸŸ¡ é©ä¸­"
                else:
                    quality = "ğŸ”´ ç°¡çŸ­"
                st.metric("å›ç­”è©³ç´°åº¦", quality)
    else:
        st.warning("æœªèƒ½ç”¢ç”Ÿ AI å›ç­”")

def display_process_flow(result: Dict):
    """é¡¯ç¤ºè™•ç†æµç¨‹"""
    st.subheader("ğŸ”„ è™•ç†æµç¨‹")
    
    # æµç¨‹åœ–
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.success("âœ… 1. å•é¡Œè¼¸å…¥")
        st.write("âœ“ æ¥æ”¶ä½¿ç”¨è€…å•é¡Œ")
    
    with col2:
        st.success("âœ… 2. ä¸»é¡Œåˆ†é¡")
        st.write(f"âœ“ é¸æ“‡ï¼š{result['chosen_topic']}")
    
    with col3:
        st.success("âœ… 3. è³‡æ–™åº«é¸æ“‡")
        if result['data_file']:
            db_name = os.path.basename(result['data_file'])
            st.write(f"âœ“ ä½¿ç”¨ï¼š{db_name}")
    
    with col4:
        st.success("âœ… 4. æ–‡ä»¶æª¢ç´¢")
        st.write(f"âœ“ æ‰¾åˆ°ï¼š{len(result['retrieved_docs'])} å€‹ç‰‡æ®µ")
    
    with col5:
        if result['answer']:
            st.success("âœ… 5. ç”¢ç”Ÿå›ç­”")
            st.write("âœ“ AI å›ç­”å®Œæˆ")
        else:
            st.error("âŒ 5. ç”¢ç”Ÿå›ç­”")
            st.write("âœ— å›ç­”å¤±æ•—")

def main():
    # æ¨™é¡Œå’Œèªªæ˜
    st.title("âš–ï¸ æ³•å¾‹æ©Ÿå™¨äººä»£ç†")
    st.markdown("è¼¸å…¥æ³•å¾‹å•é¡Œï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†é¡ä¸»é¡Œã€æª¢ç´¢ç›¸é—œè³‡æ–™ä¸¦ç”¢ç”Ÿå°ˆæ¥­å›ç­”")
    
    # è¼‰å…¥ä»£ç†
    agent = load_agent()
    if not agent:
        st.stop()
    
    # å´é‚Šæ¬„è¨­å®š
    st.sidebar.title("ğŸ”§ ç³»çµ±è¨­å®š")
    
    # ç³»çµ±ç‹€æ…‹
    st.sidebar.success("âœ… ç³»çµ±å·²å°±ç·’")
    
    # é€²éšè¨­å®š
    st.sidebar.subheader("âš™ï¸ é€²éšè¨­å®š")
    verbose_mode = st.sidebar.checkbox("è©³ç´°è™•ç†éç¨‹", value=False)
    show_process_flow = st.sidebar.checkbox("é¡¯ç¤ºè™•ç†æµç¨‹", value=True)
    
    # ç¯„ä¾‹å•é¡Œ
    st.sidebar.subheader("ğŸ’¡ ç¯„ä¾‹å•é¡Œ")
    example_questions = [
        "æŸäººæ•…æ„æ®ºå®³ä»–äººï¼Œæ‡‰è©²å¦‚ä½•è«–è™•ï¼Ÿ",
        "ç”²ç«Šå–ä»–äººè²¡ç‰©å¾Œè¢«ç™¼ç¾ï¼Œç‚ºäº†è„«å…é€®æ•è€Œä½¿ç”¨æš´åŠ›",
        "ä»€éº¼æ˜¯æº–å¼·ç›œç½ªï¼Ÿæ§‹æˆè¦ä»¶æœ‰å“ªäº›ï¼Ÿ",
        "ç«Šç›œç½ªçš„æ§‹æˆè¦ä»¶æœ‰å“ªäº›ï¼Ÿ",
        "ç”²ç”·å¼·åˆ¶ä¹™å¥³ç™¼ç”Ÿæ€§é—œä¿‚ï¼Œè§¸çŠ¯ä»€éº¼ç½ªï¼Ÿ"
    ]
    
    selected_example = st.sidebar.selectbox(
        "é¸æ“‡ç¯„ä¾‹å•é¡Œï¼š",
        ["è«‹é¸æ“‡..."] + example_questions
    )
    
    # ä¸»è¦ä»‹é¢
    st.subheader("â“ è¼¸å…¥æ‚¨çš„æ³•å¾‹å•é¡Œ")
    
    # å•é¡Œè¼¸å…¥å€åŸŸ
    col1, col2 = st.columns([4, 1])
    
    with col1:
        if selected_example and selected_example != "è«‹é¸æ“‡...":
            user_query = st.text_area(
                "è«‹è¼¸å…¥å•é¡Œï¼š",
                value=selected_example,
                height=100,
                placeholder="ä¾‹å¦‚ï¼šç”²ç«Šå–ä»–äººè²¡ç‰©å¾Œè¢«ç™¼ç¾ï¼Œç‚ºäº†è„«å…é€®æ•è€Œä½¿ç”¨æš´åŠ›ï¼Œé€™æ¨£çš„è¡Œç‚ºå¦‚ä½•å®šç½ªï¼Ÿ"
            )
        else:
            user_query = st.text_area(
                "è«‹è¼¸å…¥å•é¡Œï¼š",
                height=100,
                placeholder="ä¾‹å¦‚ï¼šç”²ç«Šå–ä»–äººè²¡ç‰©å¾Œè¢«ç™¼ç¾ï¼Œç‚ºäº†è„«å…é€®æ•è€Œä½¿ç”¨æš´åŠ›ï¼Œé€™æ¨£çš„è¡Œç‚ºå¦‚ä½•å®šç½ªï¼Ÿ"
            )
    
    with col2:
        st.write("")  # ç©ºç™½ç”¨æ–¼å°é½Š
        st.write("")  # ç©ºç™½ç”¨æ–¼å°é½Š
        query_button = st.button("ğŸ” æŸ¥è©¢", type="primary", use_container_width=True)
        clear_button = st.button("ğŸ—‘ï¸ æ¸…é™¤", use_container_width=True)
    
    # æ¸…é™¤åŠŸèƒ½
    if clear_button:
        st.session_state.last_result = None
        st.rerun()
    
    # è™•ç†æŸ¥è©¢
    if query_button and user_query.strip():
        with st.spinner('ğŸ”„ æ­£åœ¨è™•ç†æ‚¨çš„å•é¡Œ...'):
            result = agent.process_query(user_query.strip(), verbose=verbose_mode)
            st.session_state.last_result = result
    
    # é¡¯ç¤ºçµæœ
    if st.session_state.last_result:
        result = st.session_state.last_result
        
        # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤
        if result['error']:
            st.error(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{result['error']}")
            return
        
        # é¡¯ç¤ºè™•ç†æµç¨‹ï¼ˆå¯é¸ï¼‰
        if show_process_flow:
            display_process_flow(result)
            st.divider()
        
        # å»ºç«‹ä¸‰å€‹ä¸»è¦å€å¡Šçš„æ¨™ç±¤é 
        tab1, tab2, tab3 = st.tabs(["ğŸ¯ ä¸»é¡Œåˆ†é¡", "ğŸ“š åƒè€ƒè³‡æ–™", "ğŸ¤– AI å›ç­”"])
        
        with tab1:
            display_classification_result(result)
        
        with tab2:
            display_reference_data(result)
        
        with tab3:
            display_ai_response(result)
        
        # åŒ¯å‡ºåŠŸèƒ½
        st.divider()
        st.subheader("ğŸ“¤ åŒ¯å‡ºçµæœ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # åŒ¯å‡ºå®Œæ•´çµæœç‚º JSON
            import json
            export_data = {
                "query": result['user_query'],
                "topic": result['chosen_topic'],
                "database": os.path.basename(result['data_file']) if result['data_file'] else None,
                "retrieved_docs_count": len(result['retrieved_docs']),
                "answer": result['answer'],
                "timestamp": pd.Timestamp.now().isoformat()
            }
            
            json_data = json.dumps(export_data, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“„ åŒ¯å‡ºæŸ¥è©¢çµæœ (JSON)",
                data=json_data,
                file_name=f"law_query_result_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        with col2:
            # åŒ¯å‡ºå›ç­”ç‚ºæ–‡å­—æª”
            if result['answer']:
                answer_text = f"""æ³•å¾‹å•é¡Œï¼š{result['user_query']}

åˆ†é¡ä¸»é¡Œï¼š{result['chosen_topic']}

AI å›ç­”ï¼š
{result['answer']}

æŸ¥è©¢æ™‚é–“ï¼š{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
                st.download_button(
                    label="ğŸ“ åŒ¯å‡ºå›ç­” (TXT)",
                    data=answer_text,
                    file_name=f"law_answer_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )
        
        with col3:
            # åŒ¯å‡ºåƒè€ƒè³‡æ–™
            if result['retrieved_docs']:
                ref_data = []
                for i, doc in enumerate(result['retrieved_docs'], 1):
                    ref_data.append({
                        "åºè™Ÿ": i,
                        "æ¨™é¡Œ": doc.metadata.get('title', 'æœªçŸ¥'),
                        "ç« ç¯€": doc.metadata.get('section', 'æœªçŸ¥'),
                        "é¡Œç›®ç·¨è™Ÿ": doc.metadata.get('question_number', 'æœªçŸ¥'),
                        "é¡å‹": doc.metadata.get('type', 'æœªçŸ¥'),
                        "å…§å®¹": doc.page_content
                    })
                
                df = pd.DataFrame(ref_data)
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“Š åŒ¯å‡ºåƒè€ƒè³‡æ–™ (CSV)",
                    data=csv,
                    file_name=f"law_references_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )

if __name__ == "__main__":
    main()
